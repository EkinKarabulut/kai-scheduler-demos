apiVersion: v1
kind: Pod
metadata:
  name: training-job-1
  namespace: runai-project-a
  labels:
    runai/queue: project-a
spec:
  schedulerName: kai-scheduler
  containers:
  - name: training
    image: nvidia/cuda:11.8.0-base-ubuntu22.04
    resources:
      requests:
        nvidia.com/gpu: "4"
      limits:
        nvidia.com/gpu: "4"
    command: ["sleep", "3600"]
---
apiVersion: v1
kind: Pod
metadata:
  name: training-job-2
  namespace: runai-project-c
  labels:
    runai/queue: project-c
spec:
  schedulerName: kai-scheduler
  containers:
  - name: training
    image: nvidia/cuda:11.8.0-base-ubuntu22.04
    resources:
      requests:
        nvidia.com/gpu: "2"
      limits:
        nvidia.com/gpu: "2"
    command: ["sleep", "3600"]
---
apiVersion: "kubeflow.org/v1"
kind: PyTorchJob
metadata:
  name: pytorch-distributed-training
  namespace: runai-project-c
  labels:
    runai/queue: project-c
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: OnFailure
      template:
        spec:
          schedulerName: kai-scheduler
          containers:
            - args:
                - --backend
                - gloo
                - --epochs
                - "900"
                - --batch-size
                - "64"
                - --learning-rate
                - "0.01"
              image: pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime
              name: pytorch
              command: ["python"]
              resources:
                requests:
                  nvidia.com/gpu: "2"
                limits:
                  nvidia.com/gpu: "2"
    Worker:
      replicas: 2
      restartPolicy: OnFailure
      template:
        spec:
          schedulerName: kai-scheduler
          containers:
            - args:
                - --backend
                - gloo
                - --epochs
                - "900"
                - --batch-size
                - "64"
                - --learning-rate
                - "0.01"
              image: pytorch/pytorch:2.1.0-cuda11.8-cudnn8-runtime
              name: pytorch
              command: ["python"]
              resources:
                requests:
                  nvidia.com/gpu: "2"
                limits:
                  nvidia.com/gpu: "2"
---
apiVersion: v1
kind: Pod
metadata:
  name: interactive-job
  namespace: runai-project-d
  labels:
    runai/queue: project-d
spec:
  schedulerName: kai-scheduler
  priorityClassName: build  # Non-preemptible interactive job
  containers:
  - name: interactive
    image: nvidia/cuda:11.8.0-base-ubuntu22.04
    resources:
      requests:
        nvidia.com/gpu: "5"
      limits:
        nvidia.com/gpu: "5"
    command: ["sleep", "3600"] 